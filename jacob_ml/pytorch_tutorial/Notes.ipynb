{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 03 - Gradient Calculation With Autograd</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5299, grad_fn=<MeanBackward0>)\n",
      "tensor([3.1429, 1.3177, 3.7147])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "# print(x)\n",
    "\n",
    "y = x + 2\n",
    "# print(y)\n",
    "\n",
    "z = y * y * 2\n",
    "z = z.mean()\n",
    "# print(z)\n",
    "\n",
    "z.backward() # dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .backward will create a vector-jacobian product in the backgraound (J*v = x.grad). This means that .backward is\n",
    "okay with no input if z is a scalar, but it needs a vector as input if z is not, example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.1128,  1.9534, 15.5235], grad_fn=<MulBackward0>)\n",
      "tensor([4.0858, 5.2708, 3.7258])\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 2\n",
    "print(z)\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) # if z is a \n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "# Tree ways to prevent tracking the gradiant.\n",
    "# x.requires_grad_(False)\n",
    "# print(x)\n",
    "# y = x.detach()\n",
    "# print(y)\n",
    "# with torch.no_grad():\n",
    "#   y = x + 2\n",
    "#   print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "  model_output = (weights*3).sum()\n",
    "  model_output.backward()\n",
    "  print(weights.grad)\n",
    "\n",
    "  weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "optimizer = torch.optim.SGD( weights, lr=0.01 )\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 04 - Backpropagation - Theory With Example</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backwards pass\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "### update weights \n",
    "### next forward and backward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 05 - Gradient Descent with Autograd and Backpropagation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 7: w = 1.997, loss = 0.00050331\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "  return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "  return ((y_predicted - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x - y)**2\n",
    "# dMSE/dw = 1/N 2x (w*x - y)\n",
    "def gradient(x, y, y_predicted):\n",
    "  return np.dot(2*x, y_predicted - y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Traning\n",
    "learning_rate = 0.01\n",
    "n_inters = 20\n",
    "\n",
    "for epoch in range(n_inters):\n",
    "  # prediction = forward pass\n",
    "  y_pred = forward(X)\n",
    "\n",
    "  # loss\n",
    "  l = loss(Y, y_pred)\n",
    "\n",
    "  # gradiants\n",
    "  dw = gradient(X, Y, y_pred)\n",
    "\n",
    "  # update weights\n",
    "  w -= learning_rate * dw\n",
    "\n",
    "  if epoch % 2 == 0:\n",
    "    print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "  return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "  return ((y_predicted - y)**2).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Traning\n",
    "learning_rate = 0.01\n",
    "n_inters = 100\n",
    "\n",
    "for epoch in range(n_inters):\n",
    "  # prediction = forward pass\n",
    "  y_pred = forward(X)\n",
    "\n",
    "  # loss\n",
    "  l = loss(Y, y_pred)\n",
    "\n",
    "  # gradiants = backward pass\n",
    "  l.backward() # dl/dw\n",
    "\n",
    "  # update weights\n",
    "  with torch.no_grad():\n",
    "    w -= learning_rate * w.grad\n",
    "\n",
    "  # zero gradiants\n",
    "  w.grad.zero_()\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backward is not as exact as the numeriacal gradiant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 06 - Training Pipeline: Model, Loss, and Optimizer</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "  return w * x\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Traning\n",
    "learning_rate = 0.01\n",
    "n_inters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learning_rate) #SGD = stocastic gradiant decent\n",
    "\n",
    "for epoch in range(n_inters):\n",
    "  # prediction = forward pass\n",
    "  y_pred = forward(X)\n",
    "\n",
    "  # loss\n",
    "  l = loss(Y, y_pred)\n",
    "\n",
    "  # gradiants = backward pass\n",
    "  l.backward() # dl/dw\n",
    "\n",
    "  # update weights\n",
    "  optimizer.step()\n",
    "\n",
    "  # zero gradiants\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'epoch {epoch + 1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before traning: f(5) = 4.327\n",
      "epoch 1: w = 1.058, loss = 9.88688183\n",
      "epoch 11: w = 1.780, loss = 0.26534331\n",
      "epoch 21: w = 1.898, loss = 0.01585601\n",
      "epoch 31: w = 1.919, loss = 0.00887779\n",
      "epoch 41: w = 1.924, loss = 0.00820440\n",
      "epoch 51: w = 1.927, loss = 0.00772281\n",
      "epoch 61: w = 1.929, loss = 0.00727321\n",
      "epoch 71: w = 1.931, loss = 0.00684985\n",
      "epoch 81: w = 1.933, loss = 0.00645116\n",
      "epoch 91: w = 1.935, loss = 0.00607566\n",
      "Prediction after traning: f(5) = 9.870\n"
     ]
    }
   ],
   "source": [
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "out_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, out_size)\n",
    "\n",
    "# Costum model\n",
    "class LinearRegrassion(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(LinearRegrassion, self).__init__()\n",
    "    # define layers\n",
    "    self.lin = nn.Linear(input_dim, output_dim)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.lin(x)\n",
    "\n",
    "# model = LinearRegrassion(input_size, out_size)\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# Traning\n",
    "learning_rate = 0.01\n",
    "n_inters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #SGD = stocastic gradiant decent\n",
    "\n",
    "for epoch in range(n_inters):\n",
    "  # prediction = forward pass\n",
    "  y_pred = model(X)\n",
    "\n",
    "  # loss\n",
    "  l = loss(Y, y_pred)\n",
    "\n",
    "  # gradiants = backward pass\n",
    "  l.backward() # dl/dw\n",
    "\n",
    "  # update weights\n",
    "  optimizer.step()\n",
    "\n",
    "  # zero gradiants\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    [w, b] = model.parameters()\n",
    "    print(f'epoch {epoch + 1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 07 - Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD9UlEQVR4nO3de3wU9d33//ckSAAlQSAQMEHwXK03bbEiKv0RS8XWy8IdoFW4eomlUhFUwHqgHoC2FiteeFZqq+L1qKAoUe+qtaU0UXqLh2qpBcRbCpQQSEBSEqAQYDO/P4ZdstmZ3dlkd2dm9/V8PPZBMzu7+43Y7rvfw+djmKZpCgAAIKDyvB4AAABARxBmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoHXyegCZ0NLSou3bt6t79+4yDMPr4QAAABdM09TevXvVv39/5eU5z7/kRJjZvn27ysrKvB4GAABoh5qaGpWWljo+nxNhpnv37pKsfxiFhYUejwYAALjR1NSksrKyyPe4k5wIM+GlpcLCQsIMAAABk2iLCBuAAQBAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoBFmAABAoOVE0TwAAHwnFJJWrZJ27JD69ZOGD5fy870eVSARZgAAyLTKSummm6Rt245dKy2VHnpIqqjwblwBxTITAACZVFkpjRsXHWQkqbbWul5Z6c242iMUkqqrpaVLrT9DIU+GQZgBACBTQiFrRsY0Y58LX5sxw7NQkJTKSmngQKm8XJowwfpz4EBPwhhhBgCATFm1KnZGpjXTlGpqrPv8zGezS4QZAAAyZceO1N7nBR/OLhFmAADIlH79UnufF3w4u0SYAQAgU4YPt04tGYb984YhlZVZ9/mVD2eXCDMAAGRKfr51/FqKDTThnx980N/1Znw4u0SYAQAgkyoqpJdekk46Kfp6aal13e91Znw4u0TRPAAAMq2iQho9OpgVgMOzS+PGWcGl9UZgj2aXCDMAAHghP18aMcLrUbRPeHbJrorxgw9mfHaJMAMAAJLno9klwgwAAGgfn8wuEWYAAIC9gHT2JswAAIBYAerszdFsAAAQzWe9lxIhzAAAgGN82HspEcIMAAA4xoe9lxIhzAAAgGN82HspEcIMAAA4xoe9lxIhzAAAgGN82HspEcIMAAA4JoCdvQkzAAAgWsA6e1M0DwAAxPJR76VECDMAAMCeT3ovJcIyEwAACDRmZgAASJdkGzUGpLGj3xBmAABIh2QbNQaosaPfpHWZ6e2339YVV1yh/v37yzAMvfLKK1HPT5o0SYZhRD0uu+yyqHsaGho0ceJEFRYWqkePHpo8ebL27duXzmEDANAxyTZqDFhjR79Ja5jZv3+/Bg8erMcee8zxnssuu0w7duyIPJYuXRr1/MSJE7Vu3TqtWLFCr732mt5++21NmTIlncMGAKD9km3UGMDGjn6T1mWmb37zm/rmN78Z956CggKVlJTYPvfJJ5/ozTff1AcffKDzzjtPkvTII4/oW9/6lu6//371798/5WMGAKBDkmnUOGJE8vcjhuenmaqrq9WnTx+deeaZmjp1qnbv3h15bvXq1erRo0ckyEjSyJEjlZeXp/fee8/xPZubm9XU1BT1AAAgI5Jt1BjAxo6tNTZK27d7OwZPw8xll12m//mf/9HKlSv1i1/8Qm+99Za++c1vKnR0Kq2urk59+vSJek2nTp3Us2dP1dXVOb7v/PnzVVRUFHmUlZWl9fcAAOSQUEiqrpaWLrX+bLv8k2yjxgA2dpSkAwekM86QevSwCgXH+VpOO0/DzJVXXqlvf/vbOvfcczVmzBi99tpr+uCDD1RdXd2h9509e7YaGxsjj5qamtQMGACQ2yorpYEDpfJyacIE68+BA6M36CbbqDGAjR1vuUXq1k367LNj1woLvRuP58tMrZ1yyinq3bu3Nm7cKEkqKSnRzp07o+45cuSIGhoaHPfZSNY+nMLCwqgHAAAd4vbEUbKNGgPU2PGNN6wh3X//sWtf/rLU3GyFG6/4Ksxs27ZNu3fvVr+jU2nDhg3Tnj179OGHH0bu+dOf/qSWlhYNHTrUq2ECAHJNsieOkm3U6PPGjjU1Voi5/PLo65s2SR99JHXu7M24wgzTtPubSY19+/ZFZlm+/OUva+HChSovL1fPnj3Vs2dPzZs3T2PHjlVJSYn+8Y9/6NZbb9XevXv197//XQUFBZKsE1H19fVatGiRDh8+rGuuuUbnnXeelixZ4nocTU1NKioqUmNjI7M0AIDkVVdbS0qJVFVFnzgKeAXgAwek7t1jtwW9/LI0Zkz6P9/t93daj2b/5S9/UXmrv/xZs2ZJkq6++mo98cQT+vjjj/Xss89qz5496t+/vy699FL99Kc/jQQZSXruuec0ffp0ff3rX1deXp7Gjh2rhx9+OJ3DBgAgWntPHCXbqNFHjR0LC6W9e6OvTZsmPfqoN+OJJ61hZsSIEYo38fP73/8+4Xv07NkzqVkYAABSLqAnjtrj3nul2bNjr+/bJx1/fObH44av9swAAOBLATxxlKxPPrF+jbZB5sUXrW1Bfg0yEmEGAIDEAnTiKFlHjli/wtlnR1+/5BIrxIwb5824kkGYAQDADZ+fOGqPL31JOu642OuhkLRyZcaH025p3TMDAEBWqaiQRo9u34kjH51UeuYZ6fvfj72+aZM0aFDmx9NRhBkAAJLRnhNHlZVWnZrWBfdKS62lqwzO6GzbZm3taeuxx6Trr8/YMFKOMAMAQDqFKwe3Pd0brhycgSUq05TybDaWDBpkzcYEHXtmAABIl2QrB6fB6NH2Qaa5OTuCjESYAQAgfVatiu3l1JppWr0CVq1K+Ue/9pp1Sun//J/o62vWWB/rdQuCVCLMAACQLu2tHNwBDQ1WiLniiujrd95phZjBg1P2Ub7BnhkAANIlw5WDnWr6pa8Loz8wMwMAQLpkqHLwtGn2H7F3b/YHGYkwAwBA+qS5cvA771hv8/jj0derqqwQc8IJ7XrbwCHMAADaJxSSqqulpUutP9N4IifQ0lA5+MABK8RcdFH09WuusUKMTxpvZwx7ZgAAyfNJEbjA6Ejl4Da6d7c6WLeVC8tJTpiZAQAkJ1wEru2R43ARuMpKb8bld+HKwVddZf2ZZJD5+c+t2Zi2QWbnztwOMhJhBgCQDB8Ugcs169dbIeaOO6Kvv/SS9Y+8uNibcfkJYQYA4J6HReByzZEjVog555zo61//uvWPeexYb8blR+yZAQDE17rb8/r17l6TwiJwuWjwYOnjj2Ovh0L2rQlyHWEGAODMbqOvGykqAuda68DVgc21XrvhBunRR2Ovb9pkNYWEPcIMAMCeU7fneAzDOtXUwSJwScmCk1Xr1klf/GLs9ccek66/PvPjCRrCDAAgVryNvk5SUAQuaU6BK3yyqp11XDLFNJ2XjXL9hFIyWHkDAMRKtNHXTgeKwLVLwE9WGYZ9kDlwgCCTLMIMACCW2w28d94pLVli1c/fvDmzsyABPVn1wx/a91H6/e+tIXfpkvkxBR3LTACAWG438H79697VzncbuHxysmrtWuncc2OvDxxo5UC0H2EGABAr3O25ttZ+zcOLjb5tuQ1cmT5ZZcOpaTbLSanBMhMAIFaauz2nRDhwOSUFw5DKyjwNXIZhP7y6OoJMKhFmAAD20tDtOaV8HLjGjLEPMeGu1n37ZnxIWc0wzezPhk1NTSoqKlJjY6MKCwu9Hg4ABIvfC9LZ1ZkpK7OCTEcCVzt+723brI+2k/3ftqnn9vubMAMACL5UB652FOJjX0zqEWZaIcwAAFxzKsQXTittlticQsyqVdLFF6dpjDnC7fc3e2YAAAhLohDfvHn2QaZrV+tWgkzmcDQbAHKd3/fEZJKLQnxNNXtU1Mn+n0/2r3X4E2EGAHKZX5s0ehWwEhTYM2SfVg4fljrxjeqZtC4zvf3227riiivUv39/GYahV155Jep50zR19913q1+/furatatGjhypzz77LOqehoYGTZw4UYWFherRo4cmT56sffv2pXPYAJAbwntD2s5EhJs0VlZ6N66BA6XycmnCBOvPPn2kn/wk/X2WHArsGTJtg8yzz1qzMQQZb6U1zOzfv1+DBw/WY489Zvv8fffdp4cffliLFi3Se++9p+OPP16jRo3SwYMHI/dMnDhR69at04oVK/Taa6/p7bff1pQpU9I5bADIfn5t0ugUsBoapDlzrAIt6QxZbQrx/Uo/cJyNMU3pv/4rfUNBEswMkWS+/PLLkZ9bWlrMkpISc8GCBZFre/bsMQsKCsylS5eapmma69evNyWZH3zwQeSe3/3ud6ZhGGZtba3rz25sbDQlmY2NjR3/RQAgG1RVmab1fRz/UVWVuTEdOWKapaWJx2QYprl8efrGsXy5eUT5jh+f1s9GFLff356dZtq8ebPq6uo0cuTIyLWioiINHTpUq1evliStXr1aPXr00HnnnRe5Z+TIkcrLy9N7773n+N7Nzc1qamqKegAAWvFjk8ZEm2/DTFO67jrpueek6uqUzx4ZYyvUSUdirjecdK7M5ZXeVz5GDM/CTF1dnSSpb5uazn379o08V1dXpz59+kQ936lTJ/Xs2TNyj5358+erqKgo8ihzKscIALnKj00akwlOu3ZJ//mf1n6agQNTsvTk1Edp0tc2yayq1on/XEOQ8amsrDMze/ZsNTY2Rh41NTVeDwkA/MWPTRrbG5w6uGH5rbfiV+995q1TpBEjcve4egB4FmZKSkokSfX19VHX6+vrI8+VlJRo586dUc8fOXJEDQ0NkXvsFBQUqLCwMOoBAGjFj00awwErWR3YsGwYVk6xe0tqxgSHZ2Fm0KBBKikp0cqVKyPXmpqa9N5772nYsGGSpGHDhmnPnj368MMPI/f86U9/UktLi4YOHZrxMQNAVvFbV+zWAStZpinV1Fj7blxwWlL69FNCTBCl9WT8vn37tHHjxsjPmzdv1po1a9SzZ08NGDBAM2bM0M9+9jOdfvrpGjRokO666y71799fY8aMkSR94Qtf0GWXXaZrr71WixYt0uHDhzV9+nRdeeWV6t+/fzqHDgC5oaJCGj3aPxWAKyqk5culKVOk3buTf32CfTdf+Yr017/GXj/9dOn//b/kPw7+kNZGk9XV1SovL4+5fvXVV2vx4sUyTVNz5szRk08+qT179ujiiy/W448/rjPOOCNyb0NDg6ZPn67f/va3ysvL09ixY/Xwww/rhBNOcD0OGk0CQMCEQtI991gzNQ0N7l9XVWW7brRpk3TqqfYvYSbGv+ia3QphBgACKtzWoLbW2hPz+ef29xmGtTy2eXPMrFK8zb3wN7ff3xRgBgD4V37+sZmWrl2tU0tSdBJx2LDsFGL+8AfpG99I+Ujhoaw8mg0AyEIuNyxff3382RiCTPZhZgYAEBxxNiw3Nko9eti/jCWl7EaYAQAES+ulp6OcZmIOH6ajdS5gmQkAEFhO9WIeecSajSHI5Ab+mgEA/hM+xeRQ++a++6TbbrN/KUtKuYcwAwBBleALP7AqK6WbboruoF1aKj30kEKjKxxnWwgxuYswAwBBFOcLP9CdnSsrrePXbZNJba2Msfa/1+7dUs+eGRgbfIs9MwAQNOEv/NZBRupw92jPhUJWQGsTZAyZMsyWmNvPP9+6lSADwgwABInDF76kDnWP9oVVq6IC2m80UYbs145MU3rvvUwNDH7HMhMABEmbL/wYrbtH2/QoSol07dVp1STSMcTIkJYskXRVxz8PWYOZGQAIkgRdoZO+L1mVldLJJ0vl5dKECdafJ5+cmqWtfv2sJSWbIPMXDbGCzNH7gNaYmQGAIHH7RZ6OL/zKSmns2NjrtbXW9eXL27352KoVM8L2uUiIkaRevayZIKAVZmYAIEiGD7dOLTmVvDUMqaws9V/4oZA0ZUr8e6ZMSXqvzv/9v3H6KB2dpwESIcwAQJDk51vHr6XYFODQPTolqqutM9Dx7N5t3eeSYUgXXxx7PW6I2b3b2q8DtEKYAYCgcdk9OqXchhQX9zm1IPjviR+5m4lJ134gBBZ7ZgAgiOJ0j06p8MmltWvd3b92rRVobMbitJwkHT1VXt0kPefiM9gAjDYM08z+AtBNTU0qKipSY2OjCgsLvR4OAHgj2SPVdlWG3WpVjbiuzjl/RH0DhULSwIHWhmK7rybDsN538+bsaNuAhNx+f7PMBAC5oLLSCgqtj1QPHOh8pNqpyrBbR6sRG4Z9kGlutskrXu0HQuARZgAg2yXb/iBelWGXDLPFtgXBt75lvW3nzg4v9GI/EAKPZSYAyGbhpRunGRa7pZvqamvmph2+rVf1W33b9rmkvm2ytSM4kuL2+5sNwACQzdrT/qAdp4UOq5M667D9RyxZKl2VZPuB/Pz0tWNA1mGZCQCyWXvaHyR5WsiQaRtkatXfOmrN6SOkGWEGALJZe9ofJKoyfJRTHyXJKnzX36hLTzVioA3CDABks/a0P4h3qkjSLbovbogxZXD6CBlFmAGAbNbe484Op4oMmbpft8R8TEwLAk4fIYMIMwCQ7ZyOO590kjR3rlX0pbo6tklkRYW0ZYv0xz86Limt0EiZRp4VXv74R2nJEqmqyjodRZBBhnA0GwByRevjzp99Jv3qV9EnnVpV7Q2L24Kg9XISszBIAyoAAwCihY87FxRYMzJxiuhVVjoHmaglJZaT4APUmQGAbOGm0Fy86r6mKRmGjLH2wcQ0w59RRTE7+AphBgCygV1TSJtlo3hF9AyZsjukdP310mOPHf2BYnbwIcIMgOznx9L4qRxTuPdS29mW8LJR62UgmyJ6TsespQ61ZwIyhj0zALJbst2igzamRMtGkjRjxrGTSq2K423Uqc71YqqqCTIIDM/DzNy5c2UYRtTjrLPOijx/8OBBTZs2Tb169dIJJ5ygsWPHqr6+3sMRAwiMZLtFB3FMyfRekiJF9AyZOl0bY24/qC4yywZQtReB4nmYkaRzzjlHO3bsiDz+/Oc/R56bOXOmfvvb3+rFF1/UW2+9pe3bt6uCXfMAEkl2xiKoY0qy95LRKV/GtpqYp09Ug0wjTwXGIar2InB8EWY6deqkkpKSyKN3796SpMbGRj311FNauHChLrnkEg0ZMkTPPPOM3nnnHb377rsejxqAryU7YxHUMbnsvWRMuCruUesG9eKYNQLLFxuAP/vsM/Xv319dunTRsGHDNH/+fA0YMEAffvihDh8+rJEjR0buPeusszRgwACtXr1aF1xwge37NTc3q7m5OfJzU1NT2n8HAD6TzIxFpjYIt6eDdSLh3ku1tbYzPs0qUBcdtH2peST8ey/xz8ZooB08DzNDhw7V4sWLdeaZZ2rHjh2aN2+ehg8frrVr16qurk6dO3dWjx49ol7Tt29f1dXVOb7n/PnzNW/evDSPHICvue0W/dln1ubbREeaMzkmt/eFQ9i4cdbSkGFEBRqnzb0bN0qnnipJHLNGdvBdO4M9e/bo5JNP1sKFC9W1a1ddc801UbMsknT++eervLxcv/jFL2zfw25mpqysjHYGQC4JhayQ4jBjIcOQevaUdu+2f05K/ZKLmzGVllp9jRLNkNjVlcnPl0IhjlojawS2nUGPHj10xhlnaOPGjSopKdGhQ4e0Z8+eqHvq6+tVUlLi+B4FBQUqLCyMegDIMW66RTtJ1wbh9nawbsvhRNSk0K+dj1qbBBlkL9+FmX379ukf//iH+vXrpyFDhui4447TypUrI89/+umn2rp1q4YNG+bhKAEEglO36NJSqzeR3axMWHgz7iOPpDbQxBuTm5kghxNRhkw9q0kxtxNikAs8X2b60Y9+pCuuuEInn3yytm/frjlz5mjNmjVav369iouLNXXqVL3xxhtavHixCgsLdcMNN0iS3nnnHdefQddsIMfZbfBdtswqWOdGOvbQhEJSdbX1kKy9KyNGJJ6Vqa62iuwd5TQTs2zOOo2fe04KBgp4x+33t+cbgLdt26arrrpKu3fvVnFxsS6++GK9++67Ki4uliQ98MADysvL09ixY9Xc3KxRo0bp8ccf93jUAALFrp+Q2022kn1bgNbacxrq1Vej97z87GfuQlO4Xky8fTEypDOXSCLMIDd4PjOTCczMAIiRaDNuW06bc902eGzNqZeSi43H/zP7E1197xdsnzPVah9OVRUnlRB4br+/CTMAclc4VEjuN5a0DglOoSTsxRePvX9YOEQ5Fc+Lc6IpXtE7N69POT828ERWCexpJgDIGKfNuPGEC9rFa00QduWVVqBprR1VgA3DPshM1G9ig4yUmXYEfmzgiZxFmAGQ2yoqpC1bpAcecHd/eK9NolAiWYHnO9+J/oJPogqwU4iRJHN5pX5TOjv6YqbaEfixgSdyGstMACAlX9Bu6VL3p6HKyqyyu++8I61caW32jWOdztYXtc72OfPFl44tXXmxzNOBZTIgWYE5zQQAvhAuaDduXExbANvlm2ROQ9XUWEtZn3+e8FanU0oHVaACHZLGS7rlFum+++xPaaVbMstkbEBGhrDMBCC3hOu7LF1q/dm6IF4yBe3CDR7dShBkDJnO1XtlWEEmbMGC2L04mZKOZplABxFmAOQON5tWw3toqqqkJUusPzdvjt2H0ro1QQckCjFRG3xbmzYttZWJ3Up1s0wgBdgzAyA3dKC2S1wvvWSdWkoyWPxbXXW8/m37nGOAacuLWjKpbJYJJMDRbAAIi3eMuqNNJceNs5askmDItA0yn3wimVXV7t/Ii6WcVDXLBFKIMAMg+7WjtktEvD02YePHS8uXJ9xDE3dJyZTOOkvWXpyj7VwS8mopp6PNMoEUI8wAyH7t3bSaTGG4igpp4ULbtx2hKucQUzZA5pFWASk/X3LTf66szAo+XnG7twjIAI5mA8h+7dm06rTHxqnpZCgkzZoV85aOIcY4+v8lH3wpdklm3Djr+PWCBfbjNAx/LOV4cTQcsMHMDIDsFz5G7VRO1zCiZzras8emzVKW05LSU/q+tcE30ZLM/PnSnDlS9+7R18vKWMoB2iDMAMh+yW5abc8em1dftd4uwVHr708/PvGSTHh5a948ae9e61rPntbPLOUAMQgzALJfKGSFgZtuknr1in7OboYk2T02oZAe+lU3d/Vixo61lmacloic+h7961/S3LmR0ATgGPbMAMhulZVWiGkdDoqLpYkTpdGj7fsZJbnHxuiUL+memKdj6sUUF8fftJtoecswrOWt0aO93y8D+AgzMwCyl9Msx+efW8tODQ32oWD48NgZnNaO7rExykfYbsO5RCvtC99NnBg/hHTkCDmQw5iZAZCdOjLL8eqr0u7djm9tmC1Sjf1zcav3jh4df8z0PQLahZkZANmpvbMcoZA0ZYrtSz7Qec77YkrLjh23tuOmLgx9j4B2YWYGQHZKZpYjFLJCzY4d0vbttrMyTiHm4EGpoEBS5UPWkpZhRM8GJVPiP3yEPFHfIy+L5QE+RJgBkJ3czl589pl1DNphFscpxEiyKveGA0q4xH/bzcalpVaQcXOcOnyEvKOhCMgxdM0GkJ3cdHfu2dNxb0zcEBPeF2PXtbr1LE+/fvanpRKxO4FVVuY+FAFZwu33NzMzALKTm1kOG/t0vLprn+1zMZt77ZayUlHiv6LC2izc0VAE5Ag2AAPIXvG6O8+dGzMrY8i0DTJrNNj+lFI6N+KGQ9FVV8UvsgeAmRkAWc5plmPZssgtrpaU2vK6azWACMIMgOxnt/TTr5966XM1yL44Xtx6MX7pWg1AEstMAHKUUT7CNshE+igZhlUFuHfv6BvoWg34DmEGQE4xDPv9v/+tWcdmY8I3PPmkVFdnnVpasiRxt2sAnmCZCUBOiHOASWZpWfzaMB09nQQgrQgzALyViroscdx+u/SLX9g/FzmtHdrifgxpHi+A5BFmAHjHrjhcaalVHyYFSzlOszExNfTc1oZJ83gBtA97ZgB4o7LSKmjXto1Aba11vbKy3W/ttC/mlP4HZC5ZKlVXWzMsPhkvgI6hnQGAzAu3GnDqah1uqLh5c1JLOEnvi3E7o5Km8SaF5S3kILff34GZmXnsscc0cOBAdenSRUOHDtX777/v9ZAAtNeqVc7BQLLWgWpqrPtceOedOEtKyytlGnkdm1FJ8XiTVllphanycmnCBOvPgQOZDQKOCkSYeeGFFzRr1izNmTNHH330kQYPHqxRo0Zp586dXg8NQHvY9TRq532GIV10Uez1gwePdrW+6Sb7RpPhazNmSIcOWUtPSx2WoFI43qSxvAUkFIgws3DhQl177bW65pprdPbZZ2vRokXq1q2bnn76aa+HBsCtUOhYYKivd/eaOL2PnPbFSFZOKSiQ+xmV0tL4sx5uezCluldTyGUYS3b/D5BlfB9mDh06pA8//FAjR46MXMvLy9PIkSO1evVq29c0Nzerqakp6gHAQ22XSWbOjL/fwzAcex8lCjFR3/tuZ0p27Yr+ue2sx/DhVuBx+uA44+0Qr5e3gIDwfZj5/PPPFQqF1Ldv36jrffv2VV1dne1r5s+fr6KiosijrKwsE0MFYMdpmcRpNiEcGNr0Ptq7N4kQE9bemZK2sx75+dZm4dbjSzDelPByeQsIEN+HmfaYPXu2GhsbI4+amhqvhwTkpnjLJGFtA0BpaUzvI8OQ7A4y/O1v8d864YxKPG1nPSoqrHGddFLC8aaMV8tbQMD4vmhe7969lZ+fr/o2a+z19fUqKSmxfU1BQYEKCgoyMTwgN7k9JpxomST8Xg88IPXtG/NecY9auykqEZ5RGTfOerP2VKJoPetRUSGNHp25I9LhMFZbaz/28JHwVC9vAQHj+5mZzp07a8iQIVq5cmXkWktLi1auXKlhw4Z5ODIgRyVzTNjt8kffvtJVV1lVePPz1alTnCWlI6HkMonTjEpxsbvXeznr4dXyFhAwvg8zkjRr1iz96le/0rPPPqtPPvlEU6dO1f79+3XNNdd4PTQgtyR7TLgdyySGYb+dxpRhdbVuT32Vigppy5bo7tfbtiW/qdeLei9eLG8BAROYCsCPPvqoFixYoLq6On3pS1/Sww8/rKFDh7p6LRWAgRRoTxXc8GuclkkkqVcvqb5eRif72YX7dbNu1sLoz5FS80UeDmdS9PjsPiN8b9vfI5XjiYcKwMhBbr+/AxNmOoIwA6RAdbU1E5FIVVV008bKSmnsWMfbDTn/T5CpOLMmqWofYNc8sqzMWr4JhxM/tDMAclDWtTMA4LH2HhMePdqafWnjXt3mGGTMqmrnICMdO2k0d277mka2ZrcEtXlz9CwL9V4AX/P9aSYAPtHeY8KrVkm7d0ddcgwx4ctLXQann/3MeiTTNNJOfn70bFJb1HsBfI2ZGQDutLcKbqsveOPoNt62RmqFzCVLj11I9gRRuvsUUe8F8DXCDAB32ntMuF8/xxAjWftiVujS6CCQbLG7dPcp8qqdAQBXCDMA3HM6Jty7t/TCCzHLPB99JBnlI2zfKnLU2i4IxAtOTtK5b4V6L4CvEWYAJKeiwqrY27ro3K5d0qxZUcs8hiENGRL78mZ1Pra5N14QcApOiaRr3wr1XgDf4mg2kK3SVZckQb0Vw2xxfKlZWhb/CLSd8O+xcqW12TeRtkfDU416L0DGUGemFcIMco5d7ZSOnviR4tZbiVsvJvxUR4JAogJ81HoBso7b72+OZgPZxmnmJHzix2lJxE3QsKm3sk/Hq7v22Q4lJnMkOgIdbwzxmkaybwXIaeyZAbJJKGTNyNjNXMQ78eO251Cb/SiGTNsg89nC31ofFwpZRe2WLk1c3M7NGNi3AsAGy0xANmlPy4Fkeg4dff+ELQiqqqSGBvdLXcn2PWLfCpATaGcA5JLwDMjy5e7uD8+wJDmTc8aU/y9uvRhThnXKaedO9921QyHpxhuTm00KL1dddZX1J0EGyGmEGcDvEi3VtF6eefRRd+8ZLlCXRM8hw5A++yy25kskxITt2mUtE7kNJ/fcY4UcF2MAADtsAAb8LNGpJKflGSfhEz/hAnUuarIYMiWblaunT7xZ1/xrof2L4u2NaR1OGhqkOXNcDNzdWAHkJsIM4FeJTiUtWybNnJlckJGiT/zE6SWU8Kj1sqHSVXlSi3NdmbhqaqSbb3Z/v5u+R+ylAXISy0yAH7nZy3L99fGXiNqyO/Fj03Novm6P29XaNGUFre9+t/1BRpKmT7eWpNxw0/fI7YksAFmHmRnAj9zsZXEbBKZPl8aOtZ+laFO7xal6b1SmCgetjmpqcn9vovox7a2tAyArMDMD+FEq94eMHRv/xE9FhQyzxTbIjPpSfezkUKKglWrz5iVud9Ce2joAsgZhBvAjN/tDJKtbtVNXabtu1Da3OL3cPBLSm3/tG/tEJjfilpZKd9wR/54kTmQByE6EGcCPbPayRAkHlccfP/Zz2+clx+WZv/41TogJ74txmslxG7Q6yjCsJbBEG3jdhitOQwFZizAD+FF4L4sUP6iMH590eX/DkL7yldiPPKTjrK7WiTbMJgpaqVBc7H6fi9twlakQBiDjaGcA+JldnZmyMivIJFneP172iBS9c2ofYDeuceOOvtjhf0LsmkGaptSrl1Vfxul1xcXW79u5s/Pnt0Y3bSBruf3+JswAftfB2imuQkzbF7j58o8XtKT4z9kFIbdBymksqX5PAJ4jzLRCmEHWihN09u6VnP51tw0xbbVuRtmOz4/7nNsZp2Sk4z0BeIow0wphBlkpTqsDY6z9l/emTdKgd5daReUSWbLEauSYLumo1ksFYCCruP3+pmgeEEQOReKMbTXSWPuXRG79Z5o3zLoNFOHO1+H7ly3reAAJvyeAnMJpJiBobIrEfUN/SNyCIMztse9E7QPsJNtSgBYEAFKAMAMETZsicYZM/VHfiLnNnPcT+wNDbo99Jzs7Ep4talvALtxSoG1ASfZ+AHBAmAGC5mjxN0Om7WzMKxptbfCdP9+qnrtyZWwp/4qKpOvTxJVsSwFaEABIITYAAwGT9FFryart8uSTsSElVRtmq6utJaJEwiekkr0fQE5y+/3NzAwQEC+9FKcFwdF5Gke7d1sNJ9su3YQ3zF51VfxmlIkk21KAFgQAUojTTEAAxAsxSbnpJmn06NQfV062pQAtCACkEDMzgI85dbWeN6dFZq/eyb/htm3p6R6d7AmpdJ6oApBzPA0zAwcOlGEYUY9777036p6PP/5Yw4cPV5cuXVRWVqb77rvPo9ECmeMUYiRrf+zdc/OsPTDtkY6lm2RPSKXrRBWAnOT5zMxPfvIT7dixI/K44YYbIs81NTXp0ksv1cknn6wPP/xQCxYs0Ny5c/Vke/9HHPC5LVvihJiqaplLllqbZ0MhazPv8uXWDEcy0rV0k+wJqVSfqAKQszzfM9O9e3eVlJTYPvfcc8/p0KFDevrpp9W5c2edc845WrNmjRYuXKgpU6ZkeKRAejmFmCPLKpU/6yapPLZtgSoqrD0w1dXSd75jdaOOp7Q0vUs34fG4PSGV7P0AYMPTo9kDBw7UwYMHdfjwYQ0YMEATJkzQzJkz1amTlbH+67/+S01NTXrllVcir6mqqtIll1yihoYGnXjiibbv29zcrObm5sjPTU1NKisr42g22i+NPX+cQszEidJvKuzbFth2g66stE4sxbN8OTMeAAIjEEezb7zxRj3//POqqqrSD3/4Q/385z/XrbfeGnm+rq5Offv2jXpN+Oe6ujrH950/f76Kiooij7KysvT8AsgNaSq5f9FF8ffF/ObZJAvLhZedevWKvf+EE6R586xZkHQIhazZoaWtlsEAIFPMFLvttttMSXEfn3zyie1rn3rqKbNTp07mwYMHTdM0zW984xvmlClTou5Zt26dKclcv3694xgOHjxoNjY2Rh41NTWmJLOxsTF1vyhyw/LlpmkY4fZGxx6GYT2WL0/6LQ8ciH278CNKVZXzja0fVVXRrztyxDT/+EfTHDfONLt3j763tLRdY45r+XLrfVt/Tu/eprlsWWo/B0DOaWxsdPX9nfI9MzfffLMmTZoU955TTjnF9vrQoUN15MgRbdmyRWeeeaZKSkpUX18fdU/4Z6d9NpJUUFCggoKC5AYOtJWo5L5hWDMjSdRtcZqJ2bVL6t32pHV7C8vl50uNjdYsTduxh/sepWqDrUP3bn3+ubWH55ZbJE4gAkizlIeZ4uJiFRcXt+u1a9asUV5envr06SNJGjZsmO644w4dPnxYxx13nCRpxYoVOvPMMx33ywAp06ahYwzTlGpqrPsSlNx3CjEndD2ivXsN+zDU3sJyaQhhtuJ9TtiCBdL551uBBwDSxLM9M6tXr9aDDz6ov/3tb9q0aZOee+45zZw5U//5n/8ZCSoTJkxQ586dNXnyZK1bt04vvPCCHnroIc2aNcurYSOXpKDk/tNPx6/eu/fAcc77b9wUlisttUJF670qyYSwjkj0OWHXX88eGgBp5dnR7IKCAj3//POaO3eumpubNWjQIM2cOTMqqBQVFekPf/iDpk2bpiFDhqh37966++67OZaNzOhgyX3XLQicln7CheXGjbPerPUMSPjnAwekkSOPXS8tdT8L0tHieW5fv2uXq9krAGgvumYDTkIha9akttZ+KSU8M7J5c9RyjVOIWVt0kc5pfMf+SYf3kmTN2tx0U/QsSK9eVvNIu/dx+1/pjnakdtv5WpKWLLGaWQJAEgJxNBvwtSRL7ju1IDAMyZz3E+cgI8Vf+qmosEoDV1VZoeCPf5S6dHF+H8NhD07rAaWi79Hw4Ta7lh3QMBJAGhFmgHhclNx///349WJaDoeOhaJE3Czd/P3v1myRE9M8tkclnX2P8vOlxx9PfB8NIwGkmeftDADfi1NyP16IiVi1KnGbgTC7GQy7ZSY3ZsywAte2Nm0QHnwwdVWAx4+3jl8vWGD/vGHQMBJA2hFmADfy86P2lziFmNdfl771rTYX3W6U7dUrdgbDqY6LGyeeaC1Ppbvv0X33Wcevr7/e2uwbVlaW2uAEAA4IM0ASzjlHWr/e/jnHvOF2v8iNN0YHDTd1XOKZM0f64hczEybGjZP+9/+mYSQAT3CaCXBh506pTZuwiIT/DUp0KkqyZmXq66O//JM5LWQn3gkpAAgATjMBKWIY9kEmFHI5aRLvVFTYjTdKy5ZFN2nsaB2YVBXHAwCfI8wADpyOWv/851ZOyHPz355wN+nmZmnuXKl//+jne/WyHnPmxHbkTtVx5o6GIgDwOfbMAG38+tfStdfaP5fUoqzdKaTSUmnePOn006XPPrMCjlMzyGXLrPvjLU+5QY0XAFmOmRngqCNHrJkYuyBjmu0IMuPGxR6nrq21Asxxx0m/+pVzM0hJmjVLWrjQ+s929WIMw5rVide7iRovAHIAYQaQ9b1/tDF7lH//ux2TIom6VkvWMWY3zSCLi+MX7XvyyWO/QGupLI4HAD5HmEFOO/dc+4mN+dduknkkpK5d2/GmbrpWt67HEs+OHbHtDKqqrBNKFRWuKhQDQLZjzwxy0vvvS0OH2j9nypB+JWl5T2uG5Y47kpvdSOWG2/B+lzZF+6LEqVAMALmAOjPIKfFOIZly2HvSq5e1nON2lsNtfZjeva3O10l05AaAXEKdGaANw7APMjv7DXYOMpIVOMaNszb1ujF8uBVEEm3MDTdpZL8LAHQIYQZZ73vfs88VP/qRZFZVq3jHx4nfxDStxo3hgnbxxCuS1zqojB/PfhcASAH2zCBr/fOfVv05O5GVnaVJ7G8JV9N12rvSWnhjrl2dmdbNF9nvAgAdRphBVnJa4YnZnpJsQblkNve6DSrxNvcCABIizCCrOIWY9eulL3zB5onw/pZ4R6lbSzb8EFQAIO3YM4OscO+99kFm1ChrNsY2yEjR+1vioZouAPgWMzMItKYmqajI/jnXRQcqKqTly6UpU6yTS21xuggAfI2ZGQSWYdgHmZaWdrQgqKiQ6uutJpA9e0Y/17On1U9p9Oj2DhUAkEaEGQROuMdiWytXWiHGad9MQvn50t13Szt3Roea3bulOXOso1Fua80AADKGMIPAeOkl+6DSq5cVYi65JEUf9Oqr1kxMQ0P09dra5IrnAQAygnYG8L0jR+w7WkvtWE5KJBSyZmCcTjfRZgAAMoZ2BsgKhmEfZA4cSEOQkdx1vA4XzwMA+AJhBr40frz9ktKvf23liS5d0vTBbovipbIzNgCgQziaDV/ZvFk65ZTY6716SZ9/noEBuC2Kl2zxPABA2hBm4Aumad/ROvxcxoQrAtfW2n9weM8MxfMAwDdYZoLniorsg0xDQ4aDjHSsIrDTB5smxfMAwGcIM/DMU09ZEx1NTdHXX3zRygwnnujNuAAAwcLRbGTc7t1S796x1884Q/r008yPJwpHswHAN9x+f7NnBhnlVJ03bqQOhayj0Dt2WBtvhw9PX5BI5mg23bABwBfStsx0zz336MILL1S3bt3Uo0cP23u2bt2qyy+/XN26dVOfPn10yy236MiRI1H3VFdX6ytf+YoKCgp02mmnafHixekaMtJo6FD7ILNjR4IgU1lpzZSUl0sTJlh/prOtAEezASBw0hZmDh06pPHjx2vq1Km2z4dCIV1++eU6dOiQ3nnnHT377LNavHix7r777sg9mzdv1uWXX67y8nKtWbNGM2bM0A9+8AP9/ve/T9ewkWK/+50VYt5/P/p6eI9tSUmcF1dWWu0D2s6UpLOtAEezASBw0r5nZvHixZoxY4b27NkTdf13v/ud/uM//kPbt29X3759JUmLFi3Sbbfdpl27dqlz58667bbb9Prrr2vt2rWR11155ZXas2eP3nzzTddjYM9M5h04IHXrZv+cq3/jvNq7Ev7cREez2TMDAGnn+3YGq1ev1rnnnhsJMpI0atQoNTU1ad26dZF7Ro4cGfW6UaNGafXq1XHfu7m5WU1NTVEPZI5h2AeZlpYkjlp71VYgfDRbil0XC//M0WwA8BXPwkxdXV1UkJEU+bmuri7uPU1NTTpw4IDje8+fP19FRUWRR1lZWYpHDzvf+579vpgNG6zs4bT515aXe1cqKqwW3SedFH29tNS6XlGR+s8EALRbUmHm9ttvl2EYcR8bNmxI11hdmz17thobGyOPmpoar4eU1f7yFyuo/OY30ddnzrRCzJlntuNNvd67UlEhbdkiVVVJS5ZYf27eTJABAB9K6mj2zTffrEmTJsW95xS7xjo2SkpK9H6bXaH19fWR58J/hq+1vqewsFBdu3Z1fO+CggIVFBS4GgfaLxSSOjn8G9ThnVh+aCuQn8/xawAIgKTCTHFxsYqLi1PywcOGDdM999yjnTt3qk+fPpKkFStWqLCwUGeffXbknjfeeCPqdStWrNCwYcNSMga0n9OS0aFD0nHHpeADwntXxo2zPqx1oGHvCgCglbTtmdm6davWrFmjrVu3KhQKac2aNVqzZo327dsnSbr00kt19tln63vf+57+9re/6fe//73uvPNOTZs2LTKrct1112nTpk269dZbtWHDBj3++ONatmyZZs6cma5hI4G777YPMn/+s5U3UhJkwti7AgBwIW1HsydNmqRnn3025npVVZVGHJ26/+c//6mpU6equrpaxx9/vK6++mrde++96tRq7aK6ulozZ87U+vXrVVpaqrvuuivhUldbHM3uuE2bpFNPjb3+7W9Lr76a5g/PZAVgAIBvuP3+pjcT4jJN+47W4ecAAEgX39eZgf+dcIJ9kNm7lyADAPAPwgxi/PrX1r6Y/fujry9fboWYE07wZlwAANihazYiPv9csjus9oUvSOvXZ348AAC4QZiBJOej1iwnAQD8jmWmHPfVr9oHmR07PAoyoZBUXS0tXWr9GQp5MAgAQJAQZnLU669bIeYvf4m+/vDDVog5WoQ5syorrY7V5eXShAnWnwMHWtcBAHDAMlOOOXDAvqO15PGSUmWlVe237SBqa63rFMkDADhgZiaHGIZ9kGlp8TjIhELSTTfZDyJ8bcYMlpwAALYIMzlg4kT7fTEbNlhZwWnzb8asWiVt2+b8vGlKNTXWfQAAtEGYyWIffGAFlSVLoq/PmmXlgzPP9GZcMXbsSO19AICcwp6ZLBQKSZ0c/mZ9edS6X7/U3gcAyCnMzGQZw7APMocP+zTISFbjyNJS5/Uuw5DKyqz7AABogzCTJe680z4L/PnPVohxmqnxhfx86aGHrP/c9pcI//zgg3TKBgDYIswE3KZN1vf9PfdEXx8zxgoxF13kybCSV1FhHb8+6aTo66WlHMsGAMTl5/+/jjhM076jdfi5QKqokEaPtk4t7dhh7ZEZPpwZGQBAXISZADr+eOnf/469vndvFnS0zs+XRozwehQAgABhmSlAli61lpTaBpnly63ZmMAHGQAA2oGZmQBoapKKimKvf+EL0vr1mR8PAAB+QpjxOafTyoHdFwMAQIqxzORTf/yjfZD5178IMgAAtEaY8ZkdO6wQ841vRF//3e+sENOjhyfDAgDAtwgzPhEKSZdcIvXvH339+eetEHPZZd6MCwAAvyPM+MDChVaF3qqqY9cmT5ZaWqTvfte7cQEAEARsAPbQe+9JF1wQfa24WPrHP6Tu3b0ZEwAAQUOY8UBDg1Xc9tCh6Otr1kiDB3syJAAAAotlpgwyTek735F69YoOMr/8pfUcQQYAgOQxM5MhTz9t7YNpbfRoqbLSuccSAABIjDCTZmvXSueeG33NMKSdO6Xevb0ZEwAA2YQ5gTTZt886Zt02yPz5z9YpJYIMAACpQZhJMdOUpk61TiPt2HHs+r33Ws9ddJF3YwMAIBuxzJRClZXS2LHR1y6+2Kof04l/0gAApAVfsSmwaZN06qmx12tqpNLSzI8HAIBcwjJTBzQ3S//rf8UGmTfftJaUCDIAAKRf2sLMPffcowsvvFDdunVTD4fuiIZhxDyef/75qHuqq6v1la98RQUFBTrttNO0ePHidA05aVOmSH//+7Gfb73VCjGjRnk3JgAAck3alpkOHTqk8ePHa9iwYXrqqacc73vmmWd0Wasuiq2Dz+bNm3X55Zfruuuu03PPPaeVK1fqBz/4gfr166dRPkgM4ZNKZ50l/fWvUpcu3o4HAIBcZJimaabzAxYvXqwZM2Zoz549sR9uGHr55Zc1ZswY29fedtttev3117V27drItSuvvFJ79uzRm2++6XoMTU1NKioqUmNjowoLC5P9FQAAgAfcfn97vmdm2rRp6t27t84//3w9/fTTap2tVq9erZEjR0bdP2rUKK1evTruezY3N6upqSnqAQAAspOnp5l+8pOf6JJLLlG3bt30hz/8Qddff7327dunG2+8UZJUV1envn37Rr2mb9++ampq0oEDB9S1a1fb950/f77mzZuX9vEDAADvJTUzc/vtt9tu2m392LBhg+v3u+uuu3TRRRfpy1/+sm677TbdeuutWrBgQdK/RFuzZ89WY2Nj5FFTU9Ph9wQAAP6U1MzMzTffrEmTJsW955RTTmn3YIYOHaqf/vSnam5uVkFBgUpKSlRfXx91T319vQoLCx1nZSSpoKBABQUF7R4HAAAIjqTCTHFxsYqLi9M1Fq1Zs0YnnnhiJIgMGzZMb7zxRtQ9K1as0LBhw9I2BgAAECxp2zOzdetWNTQ0aOvWrQqFQlqzZo0k6bTTTtMJJ5yg3/72t6qvr9cFF1ygLl26aMWKFfr5z3+uH/3oR5H3uO666/Too4/q1ltv1fe//3396U9/0rJly/T666+na9gAACBg0nY0e9KkSXr22WdjrldVVWnEiBF68803NXv2bG3cuFGmaeq0007T1KlTde211yov79hWnurqas2cOVPr169XaWmp7rrrroRLXW1xNBsAgOBx+/2d9jozfkCYAQAgeAJTZwYAAKAjCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQCDMAACDQOnk9AMQRCkmrVkk7dkj9+knDh0v5+V6PCgAAXyHM+FVlpXTTTdK2bceulZZKDz0kVVR4Ny4AAHyGZSY/qqyUxo2LDjKSVFtrXa+s9GZcAAD4EGHGb0Iha0bGNGOfC1+bMcO6DwAAEGZ8Z9Wq2BmZ1kxTqqmx7gMAAIQZ39mxI7X3AQCQ5QgzftOvX2rvAwAgyxFm/Gb4cOvUkmHYP28YUlmZdR8AACDM+E5+vnX8WooNNOGfH3yQejMAABxFmPGjigrppZekk06Kvl5aal2nzgwAABEUzWuvdFfnraiQRo+mAjAAAAkQZtojU9V58/OlESNS934AAGQhlpmSRXVeAAB8hTCTDKrzAgDgO4SZZFCdFwAA3yHMJIPqvAAA+A4bgJPhZXXedJ+eAgAgoNI2M7NlyxZNnjxZgwYNUteuXXXqqadqzpw5OnToUNR9H3/8sYYPH64uXbqorKxM9913X8x7vfjiizrrrLPUpUsXnXvuuXrjjTfSNez4vKrOW1kpDRwolZdLEyZYfw4cyGZjAACUxjCzYcMGtbS06Je//KXWrVunBx54QIsWLdKPf/zjyD1NTU269NJLdfLJJ+vDDz/UggULNHfuXD355JORe9555x1dddVVmjx5sv76179qzJgxGjNmjNauXZuuoTvzojovp6cAAIjLME27oznpsWDBAj3xxBPatGmTJOmJJ57QHXfcobq6OnXu3FmSdPvtt+uVV17Rhg0bJEnf/e53tX//fr322muR97ngggv0pS99SYsWLXL1uU1NTSoqKlJjY6MKCws7/ovY1ZkpK7OCTCrrzIRC1gyM06Zjw7BmijZvZskJAJB13H5/Z3QDcGNjo3r27Bn5efXq1fra174WCTKSNGrUKH366af617/+Fbln5MiRUe8zatQorV69OjODtlNRIW3ZIlVVSUuWWH9u3pz6NgOcngIAIKGMbQDeuHGjHnnkEd1///2Ra3V1dRo0aFDUfX379o08d+KJJ6quri5yrfU9dXV1jp/V3Nys5ubmyM9NTU2p+BWiZaI6L6enAABIKOmZmdtvv12GYcR9hJeIwmpra3XZZZdp/Pjxuvbaa1M2eCfz589XUVFR5FFWVpb2z0wLL09PAQAQEEnPzNx8882aNGlS3HtOOeWUyH/evn27ysvLdeGFF0Zt7JWkkpIS1dfXR10L/1xSUhL3nvDzdmbPnq1Zs2ZFfm5qagpmoAmfnqqtta86HN4zk+rTUwAABEjSYaa4uFjFxcWu7q2trVV5ebmGDBmiZ555Rnl50RNBw4YN0x133KHDhw/ruOOOkyStWLFCZ555pk488cTIPStXrtSMGTMir1uxYoWGDRvm+LkFBQUqKChI8jfzofDpqXHjrODSOtCk6/QUAAABk7YNwLW1tRoxYoQGDBig+++/X7t27VJdXV3UXpcJEyaoc+fOmjx5statW6cXXnhBDz30UNSsyk033aQ333xT//3f/60NGzZo7ty5+stf/qLp06ena+j+UlEhvfSSdNJJ0ddLS63rqd50DABAwKTtaPbixYt1zTXX2D7X+iM//vhjTZs2TR988IF69+6tG264QbfddlvU/S+++KLuvPNObdmyRaeffrruu+8+fetb33I9lpQfzfYCFYABADnG7fd3RuvMeCUrwgwAADnGl3VmAAAAUo0wAwAAAo0wAwAAAo0wAwAAAo0wAwAAAo0wAwAAAo0wAwAAAo0wAwAAAo0wAwAAAi3pRpNBFC5y3NTU5PFIAACAW+Hv7UTNCnIizOzdu1eSVFZW5vFIAABAsvbu3auioiLH53OiN1NLS4u2b9+u7t27yzAMr4eTEk1NTSorK1NNTQ39pnyAvw//4e/EX/j78J8g/J2Ypqm9e/eqf//+ystz3hmTEzMzeXl5Ki0t9XoYaVFYWOjbfwlzEX8f/sPfib/w9+E/fv87iTcjE8YGYAAAEGiEGQAAEGiEmYAqKCjQnDlzVFBQ4PVQIP4+/Ii/E3/h78N/sunvJCc2AAMAgOzFzAwAAAg0wgwAAAg0wgwAAAg0wgwAAAg0wkzAbdmyRZMnT9agQYPUtWtXnXrqqZozZ44OHTrk9dBy1j333KMLL7xQ3bp1U48ePbweTk567LHHNHDgQHXp0kVDhw7V+++/7/WQctbbb7+tK664Qv3795dhGHrllVe8HlJOmz9/vr761a+qe/fu6tOnj8aMGaNPP/3U62F1GGEm4DZs2KCWlhb98pe/1Lp16/TAAw9o0aJF+vGPf+z10HLWoUOHNH78eE2dOtXroeSkF154QbNmzdKcOXP00UcfafDgwRo1apR27tzp9dBy0v79+zV48GA99thjXg8Fkt566y1NmzZN7777rlasWKHDhw/r0ksv1f79+70eWodwNDsLLViwQE888YQ2bdrk9VBy2uLFizVjxgzt2bPH66HklKFDh+qrX/2qHn30UUlWb7aysjLdcMMNuv322z0eXW4zDEMvv/yyxowZ4/VQcNSuXbvUp08fvfXWW/ra177m9XDajZmZLNTY2KiePXt6PQwg4w4dOqQPP/xQI0eOjFzLy8vTyJEjtXr1ag9HBvhTY2OjJAX+O4Mwk2U2btyoRx55RD/84Q+9HgqQcZ9//rlCoZD69u0bdb1v376qq6vzaFSAP7W0tGjGjBm66KKL9MUvftHr4XQIYcanbr/9dhmGEfexYcOGqNfU1tbqsssu0/jx43Xttdd6NPLs1J6/DwDws2nTpmnt2rV6/vnnvR5Kh3XyegCwd/PNN2vSpElx7znllFMi/3n79u0qLy/XhRdeqCeffDLNo8s9yf59wBu9e/dWfn6+6uvro67X19erpKTEo1EB/jN9+nS99tprevvtt1VaWur1cDqMMONTxcXFKi4udnVvbW2tysvLNWTIED3zzDPKy2PCLdWS+fuAdzp37qwhQ4Zo5cqVkU2mLS0tWrlypaZPn+7t4AAfME1TN9xwg15++WVVV1dr0KBBXg8pJQgzAVdbW6sRI0bo5JNP1v33369du3ZFnuP/iXpj69atamho0NatWxUKhbRmzRpJ0mmnnaYTTjjB28HlgFmzZunqq6/Weeedp/PPP18PPvig9u/fr2uuucbroeWkffv2aePGjZGfN2/erDVr1qhnz54aMGCAhyPLTdOmTdOSJUv06quvqnv37pG9ZEVFReratavHo+sAE4H2zDPPmJJsH/DG1Vdfbfv3UVVV5fXQcsYjjzxiDhgwwOzcubN5/vnnm++++67XQ8pZVVVVtv99uPrqq70eWk5y+r545plnvB5ah1BnBgAABBqbKwAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKARZgAAQKD9/6gQ68nYU3qeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 0) prepare data\n",
    "x_np, y_np = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "x = torch.from_numpy(x_np.astype(np.float32))\n",
    "y = torch.from_numpy(y_np.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "# 1) model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "  # forward pass and loss\n",
    "  y_pred = model(x)\n",
    "  loss = criterion(y_pred, y)\n",
    "\n",
    "  # backward pass\n",
    "  loss.backward()\n",
    "\n",
    "  # update\n",
    "  optimizer.step()\n",
    "\n",
    "  # empty gradients\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "if epoch+1 % 10 == 0:\n",
    "  print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# plot\n",
    "predicted = model(x).detach().numpy()\n",
    "plt.plot(x_np, y_np, 'ro')\n",
    "plt.plot(x_np, predicted, 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 08 - Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss = 0.7603\n",
      "epoch: 11, loss = 0.5801\n",
      "epoch: 21, loss = 0.4768\n",
      "epoch: 31, loss = 0.4114\n",
      "epoch: 41, loss = 0.3664\n",
      "epoch: 51, loss = 0.3333\n",
      "epoch: 61, loss = 0.3079\n",
      "epoch: 71, loss = 0.2876\n",
      "epoch: 81, loss = 0.2709\n",
      "epoch: 91, loss = 0.2570\n",
      "accuracy = 0.8947\n"
     ]
    }
   ],
   "source": [
    "# 0) prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "x, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "  def __init__(self, n_input_features):\n",
    "    super(LogisticRegression, self).__init__()\n",
    "    self.linear = nn.Linear(n_input_features, 1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    y_pred = torch.sigmoid(self.linear(x))\n",
    "    return y_pred\n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "\n",
    "# 2) loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss() # Binary cross entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "  # forward pass and loss\n",
    "  y_pred = model(x_train)\n",
    "  loss = criterion(y_pred, y_train)\n",
    "\n",
    "  # backward pass\n",
    "  loss.backward()\n",
    "\n",
    "  # update\n",
    "  optimizer.step()\n",
    "\n",
    "  # empty gradients\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'epoch: {epoch}, loss = {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "  y_pred = model(x_test)\n",
    "  y_pred_cls = y_pred.round()\n",
    "  acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "  print(f'accuracy = {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 09 - Dataset and DataLoader - Batch Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 0/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 5/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, input torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 0/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 5/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, input torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, input torch.Size([4, 13])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('./data/wineData.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# get first sample and unpack\n",
    "# first_data = dataset[0]\n",
    "# features, labels = first_data\n",
    "# print(features, labels)\n",
    "dataLoader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2) # num_workers = makes loading falser, is uses multiple subprocesses \n",
    "\n",
    "# dataiter = iter(dataLoader)\n",
    "# data = dataiter.next()\n",
    "# features, labels = data\n",
    "# print(features, labels)\n",
    "\n",
    "# traning loop\n",
    "num_epoch = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "  for i, (input, labels) in enumerate(dataLoader):\n",
    "    # dorward backward, update\n",
    "    if i %5 == 0:\n",
    "      print(f'epoch {epoch+1}/{num_epoch}, step {i}/{n_iterations}, input {input.shape}')\n",
    "\n",
    "# torchvision.datasets.MNIST()\n",
    "# fasion-mnist, cifar, coco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 10 - Dataset Transforms</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([[5.1080e+01, 1.3720e+01, 7.9200e+00, 6.4000e+01, 3.2000e+02, 6.5200e+00,\n",
      "         5.0000e+00, 1.7200e+00, 3.3200e+00, 1.3600e+01, 2.8000e+00, 8.4800e+00,\n",
      "         1.4880e+03],\n",
      "        [4.6480e+01, 7.9600e+00, 9.1200e+00, 7.2000e+01, 3.9200e+02, 1.2080e+01,\n",
      "         9.0400e+00, 6.8000e-01, 5.4000e+00, 1.3000e+01, 4.6400e+00, 1.1840e+01,\n",
      "         1.3800e+03]])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# dataset = torchvision.datasets.MNIST( root='./data', transform=torchvision.transforms.ToTenser() )\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('./data/wineData.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = xy[:, 1:] # size [n_samples, n_features]\n",
    "        self.y_data = xy[:, [0]] # size [n_samples, 1]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targest = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targest)\n",
    "\n",
    "class MulTransform():\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs = input * self.factor\n",
    "        return inputs, target\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features), type(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 11 - Softmax and Cross Entropy</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Softmax</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65900114 0.24243297 0.09856589]\n",
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2, 1, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(outputs)\n",
    "\n",
    "x = torch.tensor([2, 1, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross Entropy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n",
      "Loss2 numpy: 2.3026\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(actual, predicted):\n",
    "    EPS = 1e-15\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2991693317890167\n",
      "1.6241613626480103\n",
      "tensor([2, 0, 1])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3 samples\n",
    "y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# size = n_samples * n_classes = 3*3\n",
    "y_pred_good = torch.tensor([[0.01, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
    "y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "\n",
    "l1 = loss(y_pred_good, y)\n",
    "l2 = loss(y_pred_bad, y)\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "_, prediction1 = torch.max(y_pred_good, 1)\n",
    "_, prediction2 = torch.max(y_pred_bad, 1)\n",
    "print(prediction1)\n",
    "print(prediction2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Simple Nerual Network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 12 - Activation Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 13 - Feed-Forward Neural Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
      "epoch 0 / 2, step 0/600 loss = 2.3160\n",
      "epoch 0 / 2, step 100/600 loss = 0.5255\n",
      "epoch 0 / 2, step 200/600 loss = 0.2609\n",
      "epoch 0 / 2, step 300/600 loss = 0.3316\n",
      "epoch 0 / 2, step 400/600 loss = 0.3313\n",
      "epoch 0 / 2, step 500/600 loss = 0.1392\n",
      "epoch 1 / 2, step 0/600 loss = 0.1140\n",
      "epoch 1 / 2, step 100/600 loss = 0.1693\n",
      "epoch 1 / 2, step 200/600 loss = 0.1622\n",
      "epoch 1 / 2, step 300/600 loss = 0.2546\n",
      "epoch 1 / 2, step 400/600 loss = 0.1828\n",
      "epoch 1 / 2, step 500/600 loss = 0.2828\n",
      "acc = 95.48\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cpu') #torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784 # 28x28 pic\n",
    "hidden_size = 100\n",
    "num_classes = 10 # digtest 0 to 9\n",
    "num_epoch = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "  plt.subplot(2, 3, i+1)\n",
    "  plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(NeuralNet, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.l1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.l2(out)\n",
    "    return out\n",
    "  \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epoch):\n",
    "  for i, (img, labels) in enumerate(train_loader):\n",
    "    # 100, 1, 28, 28\n",
    "    # 100, 784\n",
    "    img = img.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    #forward\n",
    "    output = model(img)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    #backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i) % 100 == 0:\n",
    "      print(f'epoch {epoch} / {num_epoch}, step {i}/{n_total_steps} loss = {loss.item():.4f}')\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "  n_correct = 0\n",
    "  n_samples = 0\n",
    "  for img, labels in test_loader:\n",
    "    img = img.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(img)\n",
    "\n",
    "    # value, index (index er class label)\n",
    "    _, predictions = torch.max(output, 1)\n",
    "    n_samples += labels.shape[0]\n",
    "    n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "  acc = 100.0 * n_correct / n_samples\n",
    "  print(f'acc = {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PyTorch Tutorial 14 - Convolutional Neural Network (CNN)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Epoch [1/5], Step [2000/12500], Loss: 2.2849\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.2677\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.2341\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.2668\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.3231\n",
      "Epoch [1/5], Step [12000/12500], Loss: 1.6277\n",
      "Epoch [2/5], Step [2000/12500], Loss: 2.0229\n",
      "Epoch [2/5], Step [4000/12500], Loss: 1.7986\n",
      "Epoch [2/5], Step [6000/12500], Loss: 1.6878\n",
      "Epoch [2/5], Step [8000/12500], Loss: 1.7350\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.1807\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.8516\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.4325\n",
      "Epoch [3/5], Step [4000/12500], Loss: 1.8096\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.6112\n",
      "Epoch [3/5], Step [8000/12500], Loss: 1.6113\n",
      "Epoch [3/5], Step [10000/12500], Loss: 1.0544\n",
      "Epoch [3/5], Step [12000/12500], Loss: 1.2439\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.9567\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.0605\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.4898\n",
      "Epoch [4/5], Step [8000/12500], Loss: 1.7458\n",
      "Epoch [4/5], Step [10000/12500], Loss: 1.3725\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.2958\n",
      "Epoch [5/5], Step [2000/12500], Loss: 0.9305\n",
      "Epoch [5/5], Step [4000/12500], Loss: 0.9055\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.5920\n",
      "Epoch [5/5], Step [8000/12500], Loss: 1.5293\n",
      "Epoch [5/5], Step [10000/12500], Loss: 1.7428\n",
      "Epoch [5/5], Step [12000/12500], Loss: 0.9818\n",
      "Finished Training\n",
      "Accuracy of the network: 48.4 %\n",
      "Accuracy of plane: 56.4 %\n",
      "Accuracy of car: 69.0 %\n",
      "Accuracy of bird: 20.4 %\n",
      "Accuracy of cat: 10.7 %\n",
      "Accuracy of deer: 38.1 %\n",
      "Accuracy of dog: 49.1 %\n",
      "Accuracy of frog: 70.5 %\n",
      "Accuracy of horse: 60.0 %\n",
      "Accuracy of ship: 57.0 %\n",
      "Accuracy of truck: 52.8 %\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cpu') #torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # 3 because the are 3 colorchannels\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
