{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing data generator and training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.getcwd())\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import data_gen1\n",
    "\n",
    "np.random.seed(69)\n",
    "# torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-2.78204166 -0.50442394]\n",
      "  [ 0.69264511  2.68776457]]\n",
      "\n",
      " [[ 2.42784544  1.7955729 ]\n",
      "  [ 1.96322533  0.49412433]]] [0.44381637 0.50881422]\n"
     ]
    }
   ],
   "source": [
    "def create_data(num_points, point_size=1000, min_var0=0.1, max_var0=10, min_var1=0.1, max_var1=10, dim=1):\n",
    "    x0_var = np.random.uniform(min_var0, max_var0, num_points)\n",
    "    x1_var = np.random.uniform(min_var1, max_var1, num_points)\n",
    "    data = np.zeros([num_points, point_size, 2, dim])\n",
    "    label = np.zeros([num_points])\n",
    "\n",
    "    for i in range(num_points):\n",
    "        data[i], label[i] = data_gen1.gen_list(\n",
    "            point_size, x0_var[i], x1_var[i], dim)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "def create_data2(realisations, xy_len=1000, min_var0=0.1, max_var0=10, min_var1=0.1, max_var1=10, dim=1):\n",
    "    x0_var = np.random.uniform(min_var0, max_var0, realisations)\n",
    "    x1_var = np.random.uniform(min_var1, max_var1, realisations)\n",
    "    data = np.zeros((realisations, xy_len, 2))\n",
    "    label = np.zeros([realisations])\n",
    "\n",
    "    for i in range(realisations):\n",
    "        _test, label[i] = data_gen1.gen_list(\n",
    "            xy_len, x0_var[i], x1_var[i], dim)\n",
    "        x, y = _test[:, 0, :], _test[:, 1, :]\n",
    "\n",
    "        data[i] = np.hstack((x, y))\n",
    "\n",
    "    return data, label\n",
    "\n",
    "data, label = create_data2(2, 2)\n",
    "print(data, label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Test data import\n",
    "class Article_nn(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Article_nn, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size*2, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(64, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.sig(self.l2(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self, num_points, point_size):\n",
    "        self.samples, self.labels = create_data2(num_points, point_size)\n",
    "        self.samples = torch.from_numpy(self.samples).to(torch.float32)\n",
    "        self.labels = torch.from_numpy(self.labels).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(train_loader, learning_rate, num_epoch, input_size):\n",
    "    model = Article_nn(input_size)\n",
    "    # print(train_loader)\n",
    "    # loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # training loop\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(num_epoch):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            sample = images.reshape(5,-1).to(device)\n",
    "            labels = labels.view(labels.shape[0], 1).to(device) # makes it a column vector\n",
    "\n",
    "            # forward\n",
    "            output = model(sample)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i) % 1 == 0:\n",
    "                print(\n",
    "                    f'epoch {epoch} / {num_epoch-1}, step {i}/{n_total_steps-1} loss = {loss.item():.4f}')\n",
    "\n",
    "    print(f\"\\n#################################\\n# TEST DONE\\n#################################\\n\")\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_diff = 0\n",
    "        for images, labels in test_loader:\n",
    "            sample = images.reshape(5, -1).to(device)\n",
    "            labels = labels.view(labels.shape[0], 1).to(device)\n",
    "\n",
    "            outputs = model(sample) # trained model\n",
    "            n_diff += torch.mean(torch.abs(outputs-labels))\n",
    "            n_samples += labels.shape[0]\n",
    "            #n_correct += (pred == labels).sum().item()\n",
    "\n",
    "        acc = n_diff/n_samples\n",
    "        print(f\"accuracy = {acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 / 19, step 0/3 loss = 0.8007\n",
      "epoch 0 / 19, step 1/3 loss = 0.9169\n",
      "epoch 0 / 19, step 2/3 loss = 0.9257\n",
      "epoch 0 / 19, step 3/3 loss = 2.9313\n",
      "epoch 1 / 19, step 0/3 loss = 46.6680\n",
      "epoch 1 / 19, step 1/3 loss = 6.2802\n",
      "epoch 1 / 19, step 2/3 loss = -1.8519\n",
      "epoch 1 / 19, step 3/3 loss = -9.7304\n",
      "epoch 2 / 19, step 0/3 loss = 7.6825\n",
      "epoch 2 / 19, step 1/3 loss = 19.7181\n",
      "epoch 2 / 19, step 2/3 loss = 21.4233\n",
      "epoch 2 / 19, step 3/3 loss = 20.2777\n",
      "epoch 3 / 19, step 0/3 loss = 59.3292\n",
      "epoch 3 / 19, step 1/3 loss = 31.3401\n",
      "epoch 3 / 19, step 2/3 loss = -1.2533\n",
      "epoch 3 / 19, step 3/3 loss = 33.1630\n",
      "epoch 4 / 19, step 0/3 loss = 37.2920\n",
      "epoch 4 / 19, step 1/3 loss = 36.7015\n",
      "epoch 4 / 19, step 2/3 loss = 5.0255\n",
      "epoch 4 / 19, step 3/3 loss = 41.8599\n",
      "epoch 5 / 19, step 0/3 loss = 27.0690\n",
      "epoch 5 / 19, step 1/3 loss = 18.5378\n",
      "epoch 5 / 19, step 2/3 loss = 47.0295\n",
      "epoch 5 / 19, step 3/3 loss = 28.2411\n",
      "epoch 6 / 19, step 0/3 loss = 31.2588\n",
      "epoch 6 / 19, step 1/3 loss = 4.2425\n",
      "epoch 6 / 19, step 2/3 loss = 39.2896\n",
      "epoch 6 / 19, step 3/3 loss = 46.0874\n",
      "epoch 7 / 19, step 0/3 loss = 20.0604\n",
      "epoch 7 / 19, step 1/3 loss = 51.4810\n",
      "epoch 7 / 19, step 2/3 loss = 30.5774\n",
      "epoch 7 / 19, step 3/3 loss = 18.7586\n",
      "epoch 8 / 19, step 0/3 loss = 9.8029\n",
      "epoch 8 / 19, step 1/3 loss = 33.6480\n",
      "epoch 8 / 19, step 2/3 loss = 57.8751\n",
      "epoch 8 / 19, step 3/3 loss = 19.5519\n",
      "epoch 9 / 19, step 0/3 loss = 38.2085\n",
      "epoch 9 / 19, step 1/3 loss = 10.9936\n",
      "epoch 9 / 19, step 2/3 loss = 52.0938\n",
      "epoch 9 / 19, step 3/3 loss = 19.5840\n",
      "epoch 10 / 19, step 0/3 loss = 36.5049\n",
      "epoch 10 / 19, step 1/3 loss = 23.0905\n",
      "epoch 10 / 19, step 2/3 loss = 43.7653\n",
      "epoch 10 / 19, step 3/3 loss = 17.5191\n",
      "epoch 11 / 19, step 0/3 loss = -10.3196\n",
      "epoch 11 / 19, step 1/3 loss = 34.2831\n",
      "epoch 11 / 19, step 2/3 loss = 57.3719\n",
      "epoch 11 / 19, step 3/3 loss = 39.5453\n",
      "epoch 12 / 19, step 0/3 loss = 37.5111\n",
      "epoch 12 / 19, step 1/3 loss = 38.4262\n",
      "epoch 12 / 19, step 2/3 loss = 39.7685\n",
      "epoch 12 / 19, step 3/3 loss = 5.1748\n",
      "epoch 13 / 19, step 0/3 loss = 33.4354\n",
      "epoch 13 / 19, step 1/3 loss = 3.6422\n",
      "epoch 13 / 19, step 2/3 loss = 25.7784\n",
      "epoch 13 / 19, step 3/3 loss = 58.0252\n",
      "epoch 14 / 19, step 0/3 loss = 44.0048\n",
      "epoch 14 / 19, step 1/3 loss = 32.7396\n",
      "epoch 14 / 19, step 2/3 loss = 16.4228\n",
      "epoch 14 / 19, step 3/3 loss = 27.7160\n",
      "epoch 15 / 19, step 0/3 loss = 18.0602\n",
      "epoch 15 / 19, step 1/3 loss = 19.2728\n",
      "epoch 15 / 19, step 2/3 loss = 52.4725\n",
      "epoch 15 / 19, step 3/3 loss = 31.0771\n",
      "epoch 16 / 19, step 0/3 loss = 22.3245\n",
      "epoch 16 / 19, step 1/3 loss = 59.5566\n",
      "epoch 16 / 19, step 2/3 loss = 26.7147\n",
      "epoch 16 / 19, step 3/3 loss = 12.2877\n",
      "epoch 17 / 19, step 0/3 loss = -0.6779\n",
      "epoch 17 / 19, step 1/3 loss = 31.2559\n",
      "epoch 17 / 19, step 2/3 loss = 45.1029\n",
      "epoch 17 / 19, step 3/3 loss = 45.2041\n",
      "epoch 18 / 19, step 0/3 loss = 36.1139\n",
      "epoch 18 / 19, step 1/3 loss = 29.3111\n",
      "epoch 18 / 19, step 2/3 loss = 21.8311\n",
      "epoch 18 / 19, step 3/3 loss = 33.6293\n",
      "epoch 19 / 19, step 0/3 loss = 55.9093\n",
      "epoch 19 / 19, step 1/3 loss = 58.0260\n",
      "epoch 19 / 19, step 2/3 loss = 18.3919\n",
      "epoch 19 / 19, step 3/3 loss = -11.4411\n",
      "\n",
      "#################################\n",
      "# TEST DONE\n",
      "#################################\n",
      "\n",
      "accuracy = 0.10511714220046997\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    xy_len = 100\n",
    "    batch_size = 5\n",
    "    realisations = 20\n",
    "    train_data = NumbersDataset(realisations, xy_len)\n",
    "    test_data = NumbersDataset(realisations, xy_len)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # train\n",
    "    model_trained = train(train_loader, 0.5, 20, xy_len)\n",
    "\n",
    "    # test\n",
    "    test(model_trained, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}