{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST for simple introduction to coding with pytorch\n",
    "Note that if a large enough model is used (approx [784 x 128 x 1024 x 1024 x 128 x 10] in the case of NMIST) <code>.cuda()</code> should be used. Append this to the model declaration and each time we call for the data (either labels or the pure data).\n",
    "## Notes\n",
    "1. Need to understand how the data is sent to the model\n",
    "2. Need to know how to evaluate some data\n",
    "    - Here I could start feeding it noise\n",
    "    - Make sure I can see all the outputs (scalar values in the last length 10 vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use an optimizer\n",
    "# SGD = stochastic gradient descent\n",
    "# lr = learning rate\n",
    "params = model.parameters()\n",
    "optimizer = optim.SGD(params, lr=.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a cost function / loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "# to download data on device change \"download\" to \"True\"\n",
    "train_data = datasets.MNIST('data', train=True, download=False, transform=transforms.ToTensor())\n",
    "train, val = random_split(train_data, [55000, 5000])\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a training and validation loop\n",
    "t1 = time.time()\n",
    "\n",
    "n_epochs = 5 # how many times we loop through the data set\n",
    "for epoch in range(n_epochs):\n",
    "    # training loop\n",
    "    losses = []\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "\n",
    "        # x: b x 1 x 28 x 28 --> vector\n",
    "        # colour had been 3 x 28 x 28\n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1)\n",
    "\n",
    "        # step 1 (forward)\n",
    "        l = model(x) # l is logit\n",
    "\n",
    "        # step 2 (compute objective function)\n",
    "        J = loss(l, y) # y is label\n",
    "\n",
    "        # step 3 (cleaning the gradient)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # step 4 (accumulate the partial derivatives of J wrt the parameters\n",
    "        J.backward()\n",
    "\n",
    "        # step 5 (step in descent direction)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(J.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, train loss: {torch.tensor(losses).mean():.2f}\")\n",
    "\n",
    "    # validation loop\n",
    "    losses = []\n",
    "    for batch in val_loader:\n",
    "        x, y = batch\n",
    "\n",
    "        # x: b x 1 x 28 x 28 --> vector\n",
    "        # colour had been 3 x 28 x 28\n",
    "        b = x.size(0)\n",
    "        x = x.view(b, -1)\n",
    "\n",
    "        # step 1 (forward)\n",
    "        with torch.no_grad():\n",
    "            l = model(x) # l is logit\n",
    "\n",
    "        # step 2 (compute objective function)\n",
    "        J = loss(l, y) # y is label\n",
    "\n",
    "        losses.append(J.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, validation loss: {torch.tensor(losses).mean():.2f}\")\n",
    "t2 = time.time()\n",
    "print(f\"Took {t2-t1:.2f} seconds to compute\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}